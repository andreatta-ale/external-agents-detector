{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40193d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard packages imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "pd.set_option('future.no_silent_downcasting', True)\n",
    "plt.style.use('ggplot')\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3093ef4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading complete shift list from analysis script\n",
    "data_clf = pd.DataFrame(pd.read_csv('./data/source_data/res/complete_shifts_clf.csv',sep=';'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2df252",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e6f484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing target labels for numeric values\n",
    "data_clf = data_clf.replace({'C': 0, 'T': 1})\n",
    "data_clf.head()#[data_clf.time == 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3584174-813d-42b1-b829-85ed8fecdd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating control list to be bootstrapped,\n",
    "# considering only frequency shifts at time 30 minutes\n",
    "c_list_to_bootstrap = data_clf[\n",
    "    (data_clf['group'] == 0) & (data_clf['time'] == 30)\n",
    "].drop(columns=['time']).values.tolist()\n",
    "c_list_to_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be64d1bd-dfb2-4696-ab81-32e5cf9bef78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating test list to be bootstrapped,\n",
    "# considering only frequency shifts at time 30 minutes\n",
    "t_list_to_bootstrap = data_clf[\n",
    "(data_clf['group'] == 1) & (data_clf['time'] == 30)\n",
    "].drop(columns=['time']).values.tolist()\n",
    "t_list_to_bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c31c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "n = 4000\n",
    "\n",
    "# Initializing a list to store the control data\n",
    "c_data = []\n",
    "t_data = []\n",
    "\n",
    "# Generating n random data points based on the minimized control and test data\n",
    "for _ in range(n):\n",
    "    c_original = random.choice(c_list_to_bootstrap)\n",
    "    c_data.append(c_original)\n",
    "    \n",
    "    t_original = random.choice(t_list_to_bootstrap)\n",
    "    t_data.append(t_original)\n",
    "\n",
    "\n",
    "# Shuffling the data\n",
    "random.shuffle(c_data)\n",
    "random.shuffle(t_data)\n",
    "\n",
    "# Creating final list \n",
    "complete_list = c_data + t_data\n",
    "random.shuffle(complete_list)\n",
    "\n",
    "# Example of the first 3 data points\n",
    "for i in range(3):\n",
    "    print(c_data[i])\n",
    "    print(t_data[i])\n",
    "    print(complete_list[i])\n",
    "    print('----------------------\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f993eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bootstrapped dataframe\n",
    "bootstrapped = pd.DataFrame(complete_list, columns = ['group','frequency_shift','standard_deviation']) \n",
    "bootstrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f7b984",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking data distribution\n",
    "fig, axs = plt.subplots(ncols=2, figsize= (10,5))\n",
    "sns.violinplot(\n",
    "    x='group', \n",
    "    y='frequency_shift', \n",
    "    data=bootstrapped, \n",
    "    hue='group', \n",
    "    inner=\"quart\", \n",
    "    ax=axs[0]\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    x='group', \n",
    "    y='frequency_shift', \n",
    "    data=bootstrapped, \n",
    "    hue='group', \n",
    "    notch=False, \n",
    "    ax=axs[1]\n",
    ")\n",
    "\n",
    "axs[0].set_xlabel(None)\n",
    "axs[1].set_xlabel(None)\n",
    "axs[0].set_ylabel(None)\n",
    "axs[1].set_ylabel(None)\n",
    "\n",
    "fig.suptitle('Frequency shift by group - Bootstrapped')\n",
    "fig.supxlabel('Group')\n",
    "fig.supylabel('Nominal shift f(t) - f(0) [MHz]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce8dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(conf_matrix, name):\n",
    "    plt.figure(figsize=(5, 2))\n",
    "    sns.heatmap(\n",
    "        conf_matrix, \n",
    "        annot=True, \n",
    "        fmt='d', \n",
    "        cmap='Blues', \n",
    "        xticklabels=[\"C\", \"T\"], \n",
    "        yticklabels=[\"C\", \"T\"]\n",
    "    )\n",
    "    \n",
    "    plt.title(f\"Confusion matrix - {name}\", fontsize=10)\n",
    "    plt.xlabel(\"Predicted\",fontsize=10)\n",
    "    plt.ylabel(\"True\",fontsize=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb4bec-323c-466c-948f-b32734a18824",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bootstrapped.iloc[:, 1:]  # Features\n",
    "y = bootstrapped.iloc[:, 0]   # Labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe6db80",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bdb7bc-7180-42fb-82c8-6b2ea485f0ad",
   "metadata": {},
   "source": [
    "## Training classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a4af8e-70a4-4cdb-8bc8-cf27c099c08c",
   "metadata": {},
   "source": [
    "#### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863fa0b-b60e-4a8a-b6c7-93d05dcfa6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Difining params for optimization\n",
    "parameters = {\n",
    "    'objective': ['binary:logistic'],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.001, 0.01, 0.1, 0.2],\n",
    "    'n_estimators': [50, 100, 200, 300]\n",
    "}\n",
    "\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': make_scorer(precision_score),\n",
    "    'recall': make_scorer(recall_score),\n",
    "    'f1': make_scorer(f1_score)\n",
    "}\n",
    "\n",
    "# Creating the model\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "# Creating GridSearchCV with diverse metrics\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_clf, \n",
    "    param_grid=parameters, \n",
    "    scoring=scoring, \n",
    "    refit='accuracy', \n",
    "    cv=5\n",
    ")\n",
    "\n",
    "# Fitting train data to the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluation results\n",
    "results = grid_search.cv_results_\n",
    "\n",
    "# Best hyperparams\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Melhores par√¢metros: {best_params}')\n",
    "\n",
    "# Printing scores\n",
    "for scorer in scoring:\n",
    "    print(f\"{scorer} scores:\")\n",
    "    print(results[f'mean_test_{scorer}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ee9a21-d8db-4e02-9b7a-a8b847d20083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving XGBoost model \n",
    "joblib.dump(grid_search, './data/source_data/res/xgboost_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4bd6a0-9771-46cc-8379-ae979204a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data sampling for testing model\n",
    "data_to_submit = [-102.67478924215538,\t23.69349016343144]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a9e8b6-0c83-4b5a-b401-5b887db4d032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing model\n",
    "loaded_model_xgb = joblib.load('./data/source_data/res/xgboost_model.joblib')\n",
    "prediction_xgb = loaded_model_xgb.predict(np.array(data_to_submit).reshape(1, -1))\n",
    "y_pred_valor = grid_search.predict(X_test)\n",
    "\n",
    "if prediction_xgb[0] == 1:\n",
    "    print(f\"External agent detected, prediction for XGB is {prediction_xgb.item()} - positive\")\n",
    "else:\n",
    "    print(f\"External agent not detected, prediction for XGB is {prediction_xgb.item()} - negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b0cb4b-9c53-4fe9-939d-f8c283b5702e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating error\n",
    "conf_matrix = confusion_matrix(y_test,y_pred_valor)\n",
    "plot_confusion_matrix(conf_matrix, 'XGBoost')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2496f09c-a785-401a-a41e-e9ad9d608b8d",
   "metadata": {},
   "source": [
    "## Other studies\n",
    "### Logistic Regression and Random Forrest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a760f3-8d86-431e-adcb-4177102ab52e",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21147a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.special import expit\n",
    "\n",
    "clf_lr = LogisticRegression(random_state=0).fit(X_train,y_train)\n",
    "w1 = clf_lr.coef_[0][0]\n",
    "w0 = clf_lr.intercept_[0]\n",
    "\n",
    "# Expit\n",
    "values_x = np.linspace(X_train.min(),X_train.max(),100)\n",
    "values_y = expit(w1 * values_x + w0)\n",
    "curve_y = expit(w1 * X_train + w0)\n",
    "\n",
    "# Verifying prediction probabilities\n",
    "y_pred = clf_lr.predict_proba(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1962854-baa6-48cc-8767-5505b2e2e198",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_valor = clf_lr.predict(X_test)\n",
    "y_pred_valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6e54d2-584e-4bf8-9e68-571b456f2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(clf_lr, './data/source_data/res/logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f2b40e-a93a-46dc-8fd6-fb7f9fed6614",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Creating classifier\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "# Evaluating metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Evaluating with cross validation\n",
    "scores = cross_val_score(clf_rf, X, y, cv=5)\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Mean Accuracy:\", scores.mean())\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf_rf.fit(X_train, y_train)\n",
    "\n",
    "# Saving Random Forest model\n",
    "joblib.dump(clf_rf, './data/source_data/res/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51481743-9dfd-4f8e-9634-fe34aa0c8249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading models\n",
    "loaded_model_lr = joblib.load('./data/source_data/res/logistic_regression_model.pkl')\n",
    "loaded_model_rf = joblib.load('./data/source_data/res/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b138e9-c1af-4b55-98aa-d4772293e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using loaded models with data to submit sample\n",
    "# Logistic Regression\n",
    "prediction_lr = loaded_model_lr.predict(np.array(data_to_submit).reshape(1, -1))\n",
    "\n",
    "# Random Forest\n",
    "prediction_rf = loaded_model_rf.predict(np.array(data_to_submit).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20595963-a80f-420b-bf68-e89f47927a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prediction_lr)\n",
    "print(prediction_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
